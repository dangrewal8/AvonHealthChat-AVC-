# Development Environment Configuration
# This file is for local development only
# DO NOT commit real credentials to version control

# ==============================================================================
# Environment
# ==============================================================================
NODE_ENV=development

# ==============================================================================
# Server Configuration
# ==============================================================================
PORT=3001

# ==============================================================================
# AI Provider Selection
# ==============================================================================
# Choose which providers to use for embeddings and LLM
# Options: 'ollama' (local, HIPAA compliant) or 'openai' (cloud API)
# For local development, Ollama is recommended for speed and privacy

EMBEDDING_PROVIDER=ollama
LLM_PROVIDER=ollama

# ==============================================================================
# Ollama Configuration (Local AI Processing - HIPAA Compliant)
# ==============================================================================
# Make sure Ollama is running: ollama serve
# Install models: ollama pull nomic-embed-text && ollama pull llama3

OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_EMBEDDING_MODEL=nomic-embed-text
OLLAMA_EMBEDDING_DIMENSIONS=768
OLLAMA_LLM_MODEL=llama3
OLLAMA_MAX_TOKENS=2000
OLLAMA_TEMPERATURE=0.0
OLLAMA_TIMEOUT=60000

# ==============================================================================
# OpenAI Configuration (Optional - Cloud API)
# ==============================================================================
# Only needed if EMBEDDING_PROVIDER=openai or LLM_PROVIDER=openai
# Uncomment and set your API key if using OpenAI

# OPENAI_KEY=sk-your_openai_key_here
# OPENAI_EMBEDDING_MODEL=text-embedding-3-small
# OPENAI_EMBEDDING_DIMENSIONS=1536
# OPENAI_MODEL=gpt-4
# OPENAI_MAX_TOKENS=2000
# OPENAI_TEMPERATURE=0.0

# ==============================================================================
# Avon Health API Configuration
# ==============================================================================
AVON_CLIENT_ID=soXn0taz9hcA5sGbQNBKHO9ks6a9YF3x
AVON_CLIENT_SECRET=GG-RDcvPzTAKEG19YxjHZCBTVvVwcGOKPYa6z2nPkw0t4Lvl-5CjNFNRfXfrHIWc
AVON_BASE_URL=https://demo-api.avonhealth.com
AVON_ACCOUNT=prosper
AVON_USER_ID=user_3kmUMGZdObZMsmXwp0T8Pfp4e5u1

# ==============================================================================
# Vector Database Configuration
# ==============================================================================
# Using ChromaDB for development (easier setup)
# For production, use FAISS with PostgreSQL
VECTOR_DB_TYPE=chromadb

# If using FAISS (requires PostgreSQL):
# NOTE: FAISS_DIMENSION must match your embedding provider!
# - Ollama nomic-embed-text: 768
# - OpenAI text-embedding-3-small: 1536

# VECTOR_DB_TYPE=faiss
# FAISS_INDEX_PATH=./data/faiss
# FAISS_DIMENSION=768
# PG_HOST=localhost
# PG_PORT=5432
# PG_DATABASE=avon_rag_dev
# PG_USER=postgres
# PG_PASSWORD=postgres

# ==============================================================================
# Cache Configuration
# ==============================================================================
CACHE_ENABLED=true
CACHE_TTL_SECONDS=300

# ==============================================================================
# Performance Configuration
# ==============================================================================
MAX_EMBEDDING_BATCH_SIZE=100
RETRIEVAL_TOP_K=10

# ==============================================================================
# CORS Configuration
# ==============================================================================
CORS_ORIGIN=http://localhost:3000,http://localhost:5173

# ==============================================================================
# Logging Configuration
# ==============================================================================
LOG_LEVEL=debug

# ==============================================================================
# Rate Limiting
# ==============================================================================
RATE_LIMIT_ENABLED=true
RATE_LIMIT_WINDOW_MS=900000
RATE_LIMIT_MAX_REQUESTS=1000

# ==============================================================================
# Security
# ==============================================================================
HTTPS_REDIRECT=false
IP_WHITELIST=

# ==============================================================================
# Development Notes
# ==============================================================================
# - Ollama provides fast local AI processing without API costs
# - Ollama is HIPAA compliant (no PHI leaves your machine)
# - For debugging OpenAI, set EMBEDDING_PROVIDER=openai and/or LLM_PROVIDER=openai
# - Mixed providers are supported (e.g., Ollama embeddings + OpenAI LLM)
