# ==============================================================================
# Avon Health RAG System - Environment Configuration Template
# ==============================================================================
# Copy this file to .env.development or .env.production and fill in your values

# ==============================================================================
# ⚠️ HIPAA COMPLIANCE NOTICE ⚠️
# ==============================================================================
# This system processes Protected Health Information (PHI).
# Only local Ollama provider is permitted for HIPAA compliance.
# All AI processing must remain on local infrastructure.
#
# Required Setup:
#   1. Install Ollama: curl -fsSL https://ollama.ai/install.sh | sh
#   2. Start Ollama: ollama serve
#   3. Pull models: ollama pull meditron && ollama pull nomic-embed-text
#   4. Verify: curl http://localhost:11434/api/tags
#
# See backend/IMPLEMENTATION.md for detailed setup instructions.
# ==============================================================================

# ==============================================================================
# AI Provider Selection (Ollama ONLY)
# ==============================================================================
# SECURITY: Only 'ollama' is allowed. External providers are prohibited.
EMBEDDING_PROVIDER=ollama
LLM_PROVIDER=ollama

# ==============================================================================
# Ollama Configuration (Local AI Processing - HIPAA Compliant)
# ==============================================================================
# Base URL for Ollama API
OLLAMA_BASE_URL=http://localhost:11434

# Embedding Model Configuration
OLLAMA_EMBEDDING_MODEL=nomic-embed-text
OLLAMA_EMBEDDING_DIMENSIONS=768

# LLM Model Configuration (Meditron recommended for medical use)
OLLAMA_LLM_MODEL=meditron
OLLAMA_MAX_TOKENS=4096
OLLAMA_TEMPERATURE=0.1

# Advanced Configuration
OLLAMA_TOP_P=0.9
OLLAMA_NUM_THREADS=8
OLLAMA_NUM_GPU=1

# Timeout for Ollama requests (milliseconds)
OLLAMA_TIMEOUT=120000

# ==============================================================================
# Server Configuration
# ==============================================================================
NODE_ENV=development
PORT=3001
HOST=0.0.0.0

# ==============================================================================
# Avon Health API Configuration
# ==============================================================================
AVON_CLIENT_ID=your_client_id_here
AVON_CLIENT_SECRET=your_client_secret_here
AVON_BASE_URL=https://demo-api.avonhealth.com
API_TIMEOUT=30000

# ==============================================================================
# Vector Database Configuration
# ==============================================================================
# Vector DB Type: 'chromadb' or 'faiss'
VECTOR_DB_TYPE=faiss

# FAISS Configuration
# IMPORTANT: FAISS_DIMENSION must match Ollama nomic-embed-text dimensions (768)
FAISS_INDEX_PATH=./data/faiss
FAISS_DIMENSION=768

# ==============================================================================
# PostgreSQL Configuration (Required for FAISS)
# ==============================================================================
PG_HOST=localhost
PG_PORT=5432
PG_DATABASE=avon_health_rag
PG_USER=postgres
PG_PASSWORD=your_password_here

# ==============================================================================
# CORS Configuration
# ==============================================================================
CORS_ORIGIN=http://localhost:3000,http://localhost:5173
CORS_CREDENTIALS=true

# ==============================================================================
# Cache Configuration
# ==============================================================================
CACHE_ENABLED=true
CACHE_TTL_SECONDS=300
CACHE_MAX_SIZE=100

# ==============================================================================
# Performance Configuration
# ==============================================================================
MAX_EMBEDDING_BATCH_SIZE=100
RETRIEVAL_TOP_K=10

# ==============================================================================
# Logging Configuration
# ==============================================================================
# Log Level: 'debug', 'info', 'warn', 'error'
LOG_LEVEL=info
LOG_FORMAT=json

# ==============================================================================
# Security Configuration
# ==============================================================================
HTTPS_REDIRECT=false
IP_WHITELIST=
RATE_LIMIT_ENABLED=true
RATE_LIMIT_WINDOW_MS=900000
RATE_LIMIT_MAX_REQUESTS=1000

# JWT Configuration (optional)
# JWT_SECRET=your_jwt_secret_here
# JWT_EXPIRES_IN=7d

# ==============================================================================
# Monitoring & Telemetry (optional)
# ==============================================================================
# METRICS_ENABLED=true
# METRICS_PORT=9090
# SENTRY_DSN=

# ==============================================================================
# HIPAA Compliance Checklist
# ==============================================================================
# ✓ EMBEDDING_PROVIDER=ollama (local processing only)
# ✓ LLM_PROVIDER=ollama (local processing only)
# ✓ Ollama service running locally (ollama serve)
# ✓ Required models installed:
#   - ollama pull nomic-embed-text (embeddings)
#   - ollama pull meditron (medical LLM)
# ✓ FAISS_DIMENSION=768 (matches Ollama nomic-embed-text)
# ✓ No PHI sent to external APIs
#
# SECURITY: External API providers are not supported for HIPAA compliance.
# This system is designed for local Ollama processing only.

# ==============================================================================
# Docker-specific Notes
# ==============================================================================
# When running in Docker:
# - Set HOST=0.0.0.0 to allow external connections
# - Use docker-compose.yml to manage environment variables
# - Mount volumes for persistent data (/app/data)
# - Use health checks to ensure container is healthy
# - For Ollama: expose port 11434 and ensure network connectivity
